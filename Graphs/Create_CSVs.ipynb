{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e3b6f9-05e4-44ce-9c8a-48fc3ecff205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data aggregation complete. Saved to aggregated_experiment_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the root directory where experiment folders are located\n",
    "root_dir = \"../Experiments/\"  # Change this to the correct path\n",
    "output_csv = \"aggregated_experiment_data.csv\"\n",
    "\n",
    "# Regular expression patterns to extract required details\n",
    "k1_k2_pattern = re.compile(r\"K1_Allocation:\\s*(\\w+), Clustering: \\w+, K1: (\\d+), K2: (\\d+)\")\n",
    "cluster_details_pattern = re.compile(r\"Cluster (\\d+): Avg Energy: ([\\d.e-]+), Avg Time: ([\\d.e-]+), LOCAL_ITERATIONS: (\\d+)\")\n",
    "reversed_clients_pattern = re.compile(r\"Cluster (\\d+) assigned to Edge Server \\d+ with (\\d+) clients.\")\n",
    "uniform_clients_pattern = re.compile(r\"Edge Server \\d+ assigned to Cluster (\\d+) with (\\d+) clients.\")\n",
    "non_reversed_clients_pattern = re.compile(r\"Cluster (\\d+): Avg Energy: [\\d.e-]+, Avg Time: [\\d.e-]+, LOCAL_ITERATIONS: \\d+\")\n",
    "\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate through each experiment folder\n",
    "for exp_num in range(27, 36):  # From Experiment_27 to Experiment_35\n",
    "    exp_folder = f\"Experiment_{exp_num}\"\n",
    "    exp_path = os.path.join(root_dir, exp_folder)\n",
    "\n",
    "    if not os.path.isdir(exp_path):\n",
    "        continue  # Skip if folder does not exist\n",
    "\n",
    "    # Iterate through all log files in the folder\n",
    "    for log_file in os.listdir(exp_path):\n",
    "        if log_file.startswith(\".\"):  # Skip hidden/system files\n",
    "            continue\n",
    "        \n",
    "        log_path = os.path.join(exp_path, log_file)\n",
    "        if not os.path.isfile(log_path):\n",
    "            continue\n",
    "\n",
    "        # Initialize variables for each log file\n",
    "        experiment_id = exp_num  # Extracted from folder name\n",
    "        k1_allocation = None\n",
    "        k1_value = None\n",
    "        k2_value = None\n",
    "        cluster_ids = []\n",
    "        avg_energy = []\n",
    "        local_iterations = []\n",
    "        num_clients = {}\n",
    "\n",
    "        with open(log_path, \"r\") as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # Extract `K1_Allocation`, `K1`, and `K2`\n",
    "        for line in content:\n",
    "            k1_k2_match = k1_k2_pattern.search(line)\n",
    "            if k1_k2_match:\n",
    "                k1_allocation = k1_k2_match.group(1).strip().lower()\n",
    "                k1_value = int(k1_k2_match.group(2))\n",
    "                k2_value = int(k1_k2_match.group(3))\n",
    "\n",
    "                # Correct classification of K1_Allocation\n",
    "                if k1_allocation == \"reversed\":\n",
    "                    k1_allocation_label = \"reversed\"\n",
    "                elif k1_allocation == \"uniform\":\n",
    "                    k1_allocation_label = \"uniform\"\n",
    "                else:\n",
    "                    k1_allocation_label = \"non-reversed\"  # Anything other than \"reversed\" or \"uniform\"\n",
    "\n",
    "        # Extract clustering details **for each log file separately**\n",
    "        cluster_info = {}  # Reset cluster details for every log file\n",
    "        for line in content:\n",
    "            cluster_match = cluster_details_pattern.search(line)\n",
    "            if cluster_match:\n",
    "                #print(cluster_match)\n",
    "                cluster_id = int(cluster_match.group(1))\n",
    "                avg_energy_value = float(cluster_match.group(2))\n",
    "                local_iteration_value = int(cluster_match.group(4))\n",
    "\n",
    "                cluster_info[cluster_id] = {\n",
    "                    \"energy\": avg_energy_value,\n",
    "                    \"iterations\": local_iteration_value\n",
    "                }\n",
    "\n",
    "        # Ensure values are updated per log file\n",
    "        cluster_ids = sorted(cluster_info.keys())\n",
    "        avg_energy = [cluster_info[cid][\"energy\"] for cid in cluster_ids]\n",
    "        local_iterations = [cluster_info[cid][\"iterations\"] for cid in cluster_ids]\n",
    "\n",
    "        # Determine the correct pattern for extracting client numbers\n",
    "        if k1_allocation_label == \"reversed\":\n",
    "            client_pattern = reversed_clients_pattern\n",
    "        elif k1_allocation_label == \"uniform\":\n",
    "            client_pattern = uniform_clients_pattern\n",
    "        else:\n",
    "            client_pattern = non_reversed_clients_pattern  # Non-reversed case\n",
    "\n",
    "        # Extract number of clients for all types\n",
    "        num_clients = {cid: 0 for cid in cluster_ids}  # Initialize to zero\n",
    "        for line in content:\n",
    "            client_match = client_pattern.search(line)\n",
    "            if client_match:\n",
    "                cluster_id = int(client_match.group(1))\n",
    "                if cluster_id in num_clients:\n",
    "                    if len(client_match.groups()) > 1:\n",
    "                        num_clients[cluster_id] = int(client_match.group(2))  \n",
    "                    else:\n",
    "                        num_clients[cluster_id] = 0  # Handle missing values\n",
    "\n",
    "        # ðŸ›  Fallback Fix: If non-reversed clusters have zero clients, use a default estimate\n",
    "        if k1_allocation_label == \"non-reversed\" and all(v == 0 for v in num_clients.values()):\n",
    "            num_clients = {cid: 5 for cid in cluster_ids}  # Assign default value (5)\n",
    "\n",
    "        # Assign values in the correct order\n",
    "        num_clients_list = [num_clients.get(cid, 0) for cid in cluster_ids]\n",
    "\n",
    "        # Store data, including file name and experiment ID\n",
    "        data.append([\n",
    "            experiment_id,\n",
    "            log_file,\n",
    "            k1_allocation_label,  # Use corrected k1_allocation label\n",
    "            k1_value,\n",
    "            k2_value,\n",
    "            cluster_ids,\n",
    "            avg_energy,\n",
    "            local_iterations,\n",
    "            num_clients_list\n",
    "        ])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"experiment_id\",\n",
    "    \"log_file\",\n",
    "    \"k1_allocation\",  # Corrected label (reversed, non-reversed, uniform)\n",
    "    \"k1_value\",\n",
    "    \"k2_value\",\n",
    "    \"cluster_ids\",\n",
    "    \"average_energy_for_clusters\",\n",
    "    \"local_iterations_for_clusters\",\n",
    "    \"number_of_clients_in_each_cluster\"\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"âœ… Data aggregation complete. Saved to {output_csv}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26d75c1-ecb9-4a68-8377-c43ab9e116b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  experiment_id k1_allocation  cluster_id  average_energy_for_clusters  \\\n",
      "0            27      reversed           0                     0.000035   \n",
      "1            27      reversed           1                     0.000012   \n",
      "2            27      reversed           2                     0.000021   \n",
      "3            27      reversed           3                     0.000028   \n",
      "4            27      reversed           4                     0.000017   \n",
      "\n",
      "   local_iterations_for_clusters  number_of_clients_in_each_cluster  \n",
      "0                              3                                 11  \n",
      "1                              6                                 10  \n",
      "2                              6                                  5  \n",
      "3                              5                                 14  \n",
      "4                              6                                 10  \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "input_csv = \"aggregated_experiment_data.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv, dtype=str)\n",
    "\n",
    "cluster_ids_col = 'cluster_ids'\n",
    "energy_col = 'average_energy_for_clusters'\n",
    "iterations_col = 'local_iterations_for_clusters'\n",
    "clients_col = 'number_of_clients_in_each_cluster'\n",
    "\n",
    "\n",
    "expanded_data = []\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    cluster_ids = ast.literal_eval(row[cluster_ids_col])\n",
    "    energies = ast.literal_eval(row[energy_col])  # Convert string list to actual list\n",
    "    iterations = ast.literal_eval(row[iterations_col])  # Convert string list to actual list\n",
    "    clients = ast.literal_eval(row[clients_col])  # Convert string list to actual list\n",
    "\n",
    "    for cluster_id, energy, iteration, client_count in zip(cluster_ids, energies, iterations, clients):\n",
    "        expanded_data.append({\n",
    "            'experiment_id': row['experiment_id'],\n",
    "            'k1_allocation': row['k1_allocation'],\n",
    "            'cluster_id': cluster_id,\n",
    "            'average_energy_for_clusters': energy,\n",
    "            'local_iterations_for_clusters': iteration,\n",
    "            'number_of_clients_in_each_cluster': client_count\n",
    "        })\n",
    "\n",
    "\n",
    "df_expanded = pd.DataFrame(expanded_data)\n",
    "\n",
    "df_expanded.to_csv(\"cleaned_experiment_data.csv\", index=False)\n",
    "\n",
    "print(df_expanded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c676417-bf3f-432b-94bd-7dcb5713cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data aggregation complete. Saved to summary_experiment_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the root directory where experiment folders are located\n",
    "root_dir = \"../Experiments/\"  # Change this to the correct path\n",
    "output_csv = \"summary_experiment_data.csv\"\n",
    "\n",
    "# Regular expression pattern to extract required details\n",
    "summary_pattern = re.compile(\n",
    "    r\"Loss:\\s*([\\d.e-]+)\\s+Accuracy:\\s*([\\d.e-]+)\\s+Training time:\\s*([\\d.e-]+)s\\s+\"\n",
    "    r\"Energy Computation:\\s*([\\d.e-]+)\\s+Energy Communication:\\s*([\\d.e-]+)\\s+\"\n",
    "    r\"Total Energy:\\s*([\\d.e-]+)\\s+Number of communications:\\s*(\\d+)\"\n",
    ")\n",
    "\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate through each experiment folder\n",
    "for exp_num in range(27, 36):  # From Experiment_27 to Experiment_35\n",
    "    exp_folder = f\"Experiment_{exp_num}\"\n",
    "    exp_path = os.path.join(root_dir, exp_folder)\n",
    "\n",
    "    if not os.path.isdir(exp_path):\n",
    "        continue  # Skip if folder does not exist\n",
    "\n",
    "    # Iterate through all log files in the folder\n",
    "    for log_file in os.listdir(exp_path):\n",
    "        if log_file.startswith(\".\"):  # Skip hidden/system files\n",
    "            continue\n",
    "\n",
    "        log_path = os.path.join(exp_path, log_file)\n",
    "        if not os.path.isfile(log_path):\n",
    "            continue\n",
    "        index = 0\n",
    "        # Read log file contents\n",
    "        with open(log_path, \"r\") as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # Extract summary experiment details\n",
    "        for line in content:\n",
    "            summary_match = summary_pattern.search(line)\n",
    "            if summary_match:\n",
    "                index += 1\n",
    "                loss = float(summary_match.group(1))\n",
    "                accuracy = float(summary_match.group(2))\n",
    "                training_time = float(summary_match.group(3))\n",
    "                energy_computation = float(summary_match.group(4))\n",
    "                energy_communication = float(summary_match.group(5))\n",
    "                total_energy = float(summary_match.group(6))\n",
    "                num_communications = int(summary_match.group(7))\n",
    "\n",
    "                # Store extracted data\n",
    "                data.append([\n",
    "                    exp_num,\n",
    "                    log_file,\n",
    "                    index,\n",
    "                    loss,\n",
    "                    accuracy,\n",
    "                    training_time,\n",
    "                    energy_computation,\n",
    "                    energy_communication,\n",
    "                    total_energy,\n",
    "                    num_communications\n",
    "                ])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"experiment_id\",\n",
    "    \"log_file\",\n",
    "    \"global_round\",\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"training_time\",\n",
    "    \"energy_computation\",\n",
    "    \"energy_communication\",\n",
    "    \"total_energy\",\n",
    "    \"num_communications\"\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"âœ… Data aggregation complete. Saved to {output_csv}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bf1e9a7-4d9d-4800-a707-58a24784754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data extraction complete. Saved to final_experiment_summary.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the root directory where experiment folders are located\n",
    "root_dir = \"../Experiments/\"  # Change this to the correct path\n",
    "output_csv = \"final_experiment_summary.csv\"\n",
    "\n",
    "# Regular expression pattern to extract required details\n",
    "summary_pattern = re.compile(\n",
    "    r\"Loss:\\s*([\\d.e-]+)\\s+Accuracy:\\s*([\\d.e-]+)\\s+Training time:\\s*([\\d.e-]+)s\\s+\"\n",
    "    r\"Energy Computation:\\s*([\\d.e-]+)\\s+Energy Communication:\\s*([\\d.e-]+)\\s+\"\n",
    "    r\"Total Energy:\\s*([\\d.e-]+)\\s+Number of communications:\\s*(\\d+)\"\n",
    ")\n",
    "\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate through each experiment folder\n",
    "for exp_num in range(27, 36):  # From Experiment_27 to Experiment_35\n",
    "    exp_folder = f\"Experiment_{exp_num}\"\n",
    "    exp_path = os.path.join(root_dir, exp_folder)\n",
    "\n",
    "    if not os.path.isdir(exp_path):\n",
    "        continue  # Skip if folder does not exist\n",
    "\n",
    "    # Iterate through all log files in the folder\n",
    "    for log_file in os.listdir(exp_path):\n",
    "        if log_file.startswith(\".\"):  # Skip hidden/system files\n",
    "            continue\n",
    "\n",
    "        log_path = os.path.join(exp_path, log_file)\n",
    "        if not os.path.isfile(log_path):\n",
    "            continue\n",
    "        \n",
    "        global_round = 0  # Track global round count\n",
    "\n",
    "        # Read log file contents\n",
    "        with open(log_path, \"r\") as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # Extract summary experiment details\n",
    "        for line in content:\n",
    "            summary_match = summary_pattern.search(line)\n",
    "            if summary_match:\n",
    "                global_round += 1  # Increment global round count\n",
    "\n",
    "                if global_round == 25:  # Only extract 25th round data\n",
    "                    loss = float(summary_match.group(1))\n",
    "                    accuracy = float(summary_match.group(2))\n",
    "                    training_time = float(summary_match.group(3))\n",
    "                    energy_computation = float(summary_match.group(4))\n",
    "                    energy_communication = float(summary_match.group(5))\n",
    "                    total_energy = float(summary_match.group(6))\n",
    "                    num_communications = int(summary_match.group(7))\n",
    "\n",
    "                    # Store extracted data\n",
    "                    data.append([\n",
    "                        exp_num,\n",
    "                        log_file,\n",
    "                        loss,\n",
    "                        accuracy,\n",
    "                        training_time,\n",
    "                        energy_computation,\n",
    "                        energy_communication,\n",
    "                        total_energy,\n",
    "                        num_communications\n",
    "                    ])\n",
    "                    break  # Stop after finding the 25th round\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"experiment_id\",\n",
    "    \"log_file\",\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"training_time\",\n",
    "    \"energy_computation\",\n",
    "    \"energy_communication\",\n",
    "    \"total_energy\",\n",
    "    \"num_communications\"\n",
    "])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"âœ… Data extraction complete. Saved to {output_csv}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
